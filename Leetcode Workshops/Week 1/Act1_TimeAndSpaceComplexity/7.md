**Type:** slide text

**Title:** Big - O notation

<!--title={Big-O Notationn}-->

Now that we have an understanding of *time complexity* and *space complexity* and how to express them as functions of time, we can elaborate on the way we express these functions. **Big-O Notation** is a common way to express these functions. 

Instead of using terms like *Linear Time*, *Quadratic Time*, *Logarithmic Time*, etc., we can write these terms in **Big-O Notation**. Depending on what time the function increases by, we assign it a **Big-O** value. **Big-O** notation is incredibly important because it allows us to take a more mathematical and calculated approach to understanding the way functions and algorithms grow. 

**Big-O notation** is also useful because it simplifies how we describe a function's time complexity and space complexity. So far, we have defined a function of time as a number of terms. With Big-O notation, we are able to use only the dominant, or fastest growing, term!

## How to Write in Big-O Notation

To write in **Big-O Notation** we use a capital O followed with parentheses : **O()**. 

Depending on what is inside of the parentheses will tell us what time the function grows in. Let's look at an example. 

```python
value = [1, 2, 3, 4, 5]

def valueSum(value): 
    sum = 0
    for i in value: 
        sum = sum + i
    return sum
```

Going back to our `valueSum` function, we had previously expressed the runtime of this function as input increase.  We had written the expression *Time(Input)* and the components its made of. 

**Time(Input) = c1 + c2*n + c3**

`c1` comes from the line `sum = 0` . We know `sum = 0` will always take the same amount of time to run because we are assigning a value to a variable. We call this *constant time* because no matter what function this line is in, it will take the same amount of time to run. 

Since **c1** runs in constant time, we would write it as **O(1)** in **Big-O Notation**. Notice that the line repeats only once. 

`sum = sum + i` is responsible for **c2** in our equation. We multiply **c2** by *n* however because **c2** is repeated multiple times. The runtime of this function increase linearly depending on the amount of elements that are added to `sum`. 

In **Big-O Notation**, this line would be rewritten as **O(n)** and would inform us that this line runs in *linear time*. We use the dominant term which is **c2 * n**. Since **c2 * n** and **n** behave the same (linearly), we can drop the coefficient of *c2*.

Lastly, `return sum` is written as **O(1)** because it operates under constant time. 

Rewriting our `valueSum` function but in **Big-O notation**, we would have:

```
Time(Input) = O(1) + O(n) + O(1). 
```

We've written the lines of the function in **Big-O Notation**, but now we need to write the function itself in **Big-O Notation**. The way we do that is to choose the term that is growing the fastest in the function (the dominant term) as *n* gets very large. We then disregard any coefficients of that term. Then assign that term for the function. 

For `valueSum`, the fastest growing term is **c2 * n** . If we ignore **c2** , we are left with just `n`. We now know that the time complexity of `valueSum` is **O(n)** and the runtime of `valueSum` grows in a linear fashion.

